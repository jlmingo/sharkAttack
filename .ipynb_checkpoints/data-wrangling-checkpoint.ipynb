{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.09.18.c</td>\n",
       "      <td>18-Sep-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>New Smyrna Beach, Volusia County</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orlando Sentinel, 9/19/2016</td>\n",
       "      <td>2016.09.18.c-NSB.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2016.09.18.c</td>\n",
       "      <td>2016.09.18.c</td>\n",
       "      <td>5993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016.09.18.b</td>\n",
       "      <td>18-Sep-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>New Smyrna Beach, Volusia County</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Chucky Luciano</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orlando Sentinel, 9/19/2016</td>\n",
       "      <td>2016.09.18.b-Luciano.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2016.09.18.b</td>\n",
       "      <td>2016.09.18.b</td>\n",
       "      <td>5992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016.09.18.a</td>\n",
       "      <td>18-Sep-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>New Smyrna Beach, Volusia County</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orlando Sentinel, 9/19/2016</td>\n",
       "      <td>2016.09.18.a-NSB.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2016.09.18.a</td>\n",
       "      <td>2016.09.18.a</td>\n",
       "      <td>5991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.09.17</td>\n",
       "      <td>17-Sep-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Thirteenth Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Rory Angiolella</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Age, 9/18/2016</td>\n",
       "      <td>2016.09.17-Angiolella.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2016.09.17</td>\n",
       "      <td>2016.09.17</td>\n",
       "      <td>5990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.09.15</td>\n",
       "      <td>16-Sep-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Bells Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>The Age, 9/16/2016</td>\n",
       "      <td>2016.09.16-BellsBeach.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2016.09.16</td>\n",
       "      <td>2016.09.15</td>\n",
       "      <td>5989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case Number       Date  Year        Type    Country      Area  \\\n",
       "0  2016.09.18.c  18-Sep-16  2016  Unprovoked        USA   Florida   \n",
       "1  2016.09.18.b  18-Sep-16  2016  Unprovoked        USA   Florida   \n",
       "2  2016.09.18.a  18-Sep-16  2016  Unprovoked        USA   Florida   \n",
       "3    2016.09.17  17-Sep-16  2016  Unprovoked  AUSTRALIA  Victoria   \n",
       "4    2016.09.15  16-Sep-16  2016  Unprovoked  AUSTRALIA  Victoria   \n",
       "\n",
       "                           Location Activity             Name Sex   \\\n",
       "0  New Smyrna Beach, Volusia County  Surfing             male    M   \n",
       "1  New Smyrna Beach, Volusia County  Surfing   Chucky Luciano    M   \n",
       "2  New Smyrna Beach, Volusia County  Surfing             male    M   \n",
       "3                  Thirteenth Beach  Surfing  Rory Angiolella    M   \n",
       "4                       Bells Beach  Surfing             male    M   \n",
       "\n",
       "      ...       Species        Investigator or Source  \\\n",
       "0     ...            NaN  Orlando Sentinel, 9/19/2016   \n",
       "1     ...            NaN  Orlando Sentinel, 9/19/2016   \n",
       "2     ...            NaN  Orlando Sentinel, 9/19/2016   \n",
       "3     ...            NaN           The Age, 9/18/2016   \n",
       "4     ...      2 m shark           The Age, 9/16/2016   \n",
       "\n",
       "                         pdf  \\\n",
       "0       2016.09.18.c-NSB.pdf   \n",
       "1   2016.09.18.b-Luciano.pdf   \n",
       "2       2016.09.18.a-NSB.pdf   \n",
       "3  2016.09.17-Angiolella.pdf   \n",
       "4  2016.09.16-BellsBeach.pdf   \n",
       "\n",
       "                                        href formula  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href Case Number.1  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...  2016.09.18.c   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...  2016.09.18.b   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...  2016.09.18.a   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...    2016.09.17   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...    2016.09.16   \n",
       "\n",
       "  Case Number.2 original order Unnamed: 22 Unnamed: 23  \n",
       "0  2016.09.18.c           5993         NaN         NaN  \n",
       "1  2016.09.18.b           5992         NaN         NaN  \n",
       "2  2016.09.18.a           5991         NaN         NaN  \n",
       "3    2016.09.17           5990         NaN         NaN  \n",
       "4    2016.09.15           5989         NaN         NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5992, 24)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"GSAF5.csv\", encoding = \"ISO-8859-1\")\n",
    "display(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country                     43\n",
       "Area                       402\n",
       "Location                   496\n",
       "Activity                   527\n",
       "Name                       200\n",
       "Sex                        567\n",
       "Age                       2681\n",
       "Injury                      27\n",
       "Fatal (Y/N)                 19\n",
       "Time                      3213\n",
       "Species                   2934\n",
       "Investigator or Source      15\n",
       "href formula                 1\n",
       "href                         3\n",
       "Unnamed: 22               5991\n",
       "Unnamed: 23               5990\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
      "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
      "       'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href',\n",
      "       'Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22',\n",
      "       'Unnamed: 23'],\n",
      "      dtype='object')\n",
      "\n",
      "As we can see, the two last columns are completely empty and should be removed.\n",
      "\n",
      "Columns age, time and species are c.50% empty so we will ignore them\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#First, let's take a look at null values\n",
    "\n",
    "null_cols = df.isnull().sum()\n",
    "display(null_cols[null_cols > 0])\n",
    "print(df.columns)\n",
    "print(\"\\nAs we can see, the two last columns are completely empty and should be removed.\\n\")\n",
    "print(\"Columns age, time and species are c.50% empty so we will ignore them\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Number               object\n",
      "Date                      object\n",
      "Year                       int64\n",
      "Type                      object\n",
      "Country                   object\n",
      "Area                      object\n",
      "Location                  object\n",
      "Activity                  object\n",
      "Name                      object\n",
      "Sex                       object\n",
      "Age                       object\n",
      "Injury                    object\n",
      "Fatal (Y/N)               object\n",
      "Time                      object\n",
      "Species                   object\n",
      "Investigator or Source    object\n",
      "pdf                       object\n",
      "href formula              object\n",
      "href                      object\n",
      "Case Number.1             object\n",
      "Case Number.2             object\n",
      "original order             int64\n",
      "dtype: object\n",
      "\n",
      "1) Date cannot be analyzed because it contains different types of inputs.\n",
      "3) It seems Case number and href are duplicated, we can drop these columns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_cols = list(null_cols[null_cols > 3500].index)\n",
    "df = df.drop(drop_cols, axis=1)\n",
    "\n",
    "print(df.dtypes)\n",
    "print(\"\\n1) Date cannot be analyzed because it contains different types of inputs.\")\n",
    "print(\"3) It seems Case number and href are duplicated, we can drop these columns.\\n\")\n",
    "\n",
    "drop_Case = [\"Case Number.1\", \"Case Number.2\", \"href\"]\n",
    "df = df.drop(drop_Case, axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>USA</td>\n",
       "      <td>2016.09.18.c</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Minor injury to thigh</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>USA</td>\n",
       "      <td>2016.09.18.b</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Lacerations to hands</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>USA</td>\n",
       "      <td>2016.09.18.a</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Lacerations to lower leg</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>2016.09.17</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Struck by fin on chest &amp; leg</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>2016.09.15</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>No injury: Knocked off board by shark</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year    Country   Case Number Activity  \\\n",
       "0  2016        USA  2016.09.18.c  Surfing   \n",
       "1  2016        USA  2016.09.18.b  Surfing   \n",
       "2  2016        USA  2016.09.18.a  Surfing   \n",
       "3  2016  AUSTRALIA    2016.09.17  Surfing   \n",
       "4  2016  AUSTRALIA    2016.09.15  Surfing   \n",
       "\n",
       "                                  Injury Fatal (Y/N)  \n",
       "0                  Minor injury to thigh           N  \n",
       "1                   Lacerations to hands           N  \n",
       "2               Lacerations to lower leg           N  \n",
       "3           Struck by fin on chest & leg           N  \n",
       "4  No injury: Knocked off board by shark           N  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_analysis = [\"Year\", \"Country\", \"Case Number\", \"Activity\", \"Injury\", \"Fatal (Y/N)\"]\n",
    "df = df.loc[:,col_analysis]\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing unique values for Year column\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006,\n",
       "       2005, 2004, 2003, 2002, 2001, 2000, 1999, 1998, 1997, 1996, 1995,\n",
       "       1984, 1994, 1993, 1992, 1991, 1990, 1989, 1969, 1988, 1987, 1986,\n",
       "       1985, 1983, 1982, 1981, 1980, 1979, 1978, 1977, 1976, 1975, 1974,\n",
       "       1973, 1972, 1971, 1970, 1968, 1967, 1966, 1965, 1964, 1963, 1962,\n",
       "       1961, 1960, 1959, 1958, 1957, 1956, 1955, 1954, 1953, 1952, 1951,\n",
       "       1950, 1949, 1948, 1848, 1947, 1946, 1945, 1944, 1943, 1942, 1941,\n",
       "       1940, 1939, 1938, 1937, 1936, 1935, 1934, 1933, 1932, 1931, 1930,\n",
       "       1929, 1928, 1927, 1926, 1925, 1924, 1923, 1922, 1921, 1920, 1919,\n",
       "       1918, 1917, 1916, 1915, 1914, 1913, 1912, 1911, 1910, 1909, 1908,\n",
       "       1907, 1906, 1905, 1904, 1903, 1902, 1901, 1900, 1899, 1898, 1897,\n",
       "       1896, 1895, 1894, 1893, 1892, 1891, 1890, 1889, 1888, 1887, 1886,\n",
       "       1885, 1884, 1883, 1882, 1881, 1880, 1879, 1878, 1877, 1876, 1875,\n",
       "       1874, 1873, 1872, 1871, 1870, 1869, 1868, 1867, 1866, 1865, 1864,\n",
       "       1863, 1862, 1861, 1860, 1859, 1858, 1856, 1855, 1854, 1853, 1852,\n",
       "       1851, 1850, 1849, 1847, 1846, 1845, 1844, 1842, 1841, 1840, 1839,\n",
       "       1837, 1836, 1835, 1834, 1832, 1831, 1830, 1829, 1828, 1827, 1826,\n",
       "       1825, 1822, 1819, 1818, 1817, 1816, 1812, 1811, 1807, 1805, 1804,\n",
       "       1803, 1800])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006,\n",
       "       2005, 2004, 2003, 2002, 2001, 2000, 1999, 1998, 1997, 1996, 1995,\n",
       "       1984, 1994, 1993, 1992, 1991, 1990, 1989, 1969, 1988, 1987, 1986,\n",
       "       1985, 1983, 1982, 1981, 1980, 1979, 1978, 1977, 1976, 1975, 1974,\n",
       "       1973, 1972, 1971, 1970, 1968, 1967, 1966, 1965, 1964, 1963, 1962,\n",
       "       1961, 1960, 1959, 1958, 1957, 1956, 1955, 1954, 1953, 1952, 1951,\n",
       "       1950, 1949, 1948, 1848, 1947, 1946, 1945, 1944, 1943, 1942, 1941,\n",
       "       1940, 1939, 1938, 1937, 1936, 1935, 1934, 1933, 1932, 1931, 1930,\n",
       "       1929, 1928, 1927, 1926, 1925, 1924, 1923, 1922, 1921, 1920, 1919,\n",
       "       1918, 1917, 1916, 1915, 1914, 1913, 1912, 1911, 1910, 1909, 1908,\n",
       "       1907, 1906, 1905, 1904, 1903, 1902, 1901, 1900, 1899, 1898, 1897,\n",
       "       1896, 1895, 1894, 1893, 1892, 1891, 1890, 1889, 1888, 1887, 1886,\n",
       "       1885, 1884, 1883, 1882, 1881, 1880, 1879, 1878, 1877, 1876, 1875,\n",
       "       1874, 1873, 1872, 1871, 1870, 1869, 1868, 1867, 1866, 1865, 1864,\n",
       "       1863, 1862, 1861, 1860, 1859, 1858, 1856, 1855, 1854, 1853, 1852,\n",
       "       1851, 1850, 1849, 1847, 1846, 1845, 1844, 1842, 1841, 1840, 1839,\n",
       "       1837, 1836, 1835, 1834, 1832, 1831, 1830, 1829, 1828, 1827, 1826,\n",
       "       1825, 1822, 1819, 1818, 1817, 1816, 1812, 1811, 1807, 1805, 1804,\n",
       "       1803, 1800])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will analyze these columns to further clean the data in which we are interested\n",
    "\n",
    "# 1) Analyzing Year column\n",
    "\n",
    "print(\"Showing unique values for Year column\\n\")\n",
    "display(df[\"Year\"].unique())\n",
    "\n",
    "    # Action: we will drop all values for years before 1800 as they don't seem to be reliable\n",
    "\n",
    "df = df[df[\"Year\"] >= 1800]\n",
    "df[\"Year\"].unique()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing unique values for Country column\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['USA', 'AUSTRALIA', 'NEW CALEDONIA', 'REUNION', 'BAHAMAS', 'SPAIN',\n",
       "       'CHINA', 'JAPAN', 'COLUMBIA', 'SOUTH AFRICA', 'EGYPT',\n",
       "       'NEW ZEALAND', 'INDONESIA', 'FRENCH POLYNESIA', 'CAPE VERDE',\n",
       "       'Fiji', 'BRAZIL', 'DOMINICAN REPUBLIC', 'CAYMAN ISLANDS',\n",
       "       'UNITED ARAB EMIRATES', 'ARUBA', 'MOZAMBIQUE', 'THAILAND', 'FIJI',\n",
       "       'PUERTO RICO', 'ITALY', 'MEXICO', 'ATLANTIC OCEAN', 'GREECE',\n",
       "       'MAURITIUS', nan, 'ST. MARTIN', 'FRANCE', 'ECUADOR',\n",
       "       'PAPUA NEW GUINEA', 'TRINIDAD & TOBAGO', 'KIRIBATI', 'ISRAEL',\n",
       "       'DIEGO GARCIA', 'TAIWAN', 'JAMAICA', 'PALESTINIAN TERRITORIES',\n",
       "       'GUAM', 'SEYCHELLES', 'BELIZE', 'PHILIPPINES', 'NIGERIA', 'TONGA',\n",
       "       'SCOTLAND', 'CANADA', 'CROATIA', 'SAUDI ARABIA', 'CHILE',\n",
       "       'ANTIGUA', 'KENYA', 'RUSSIA', 'TURKS & CAICOS', 'COSTA RICA',\n",
       "       'UNITED KINGDOM', 'MALAYSIA', 'UNITED ARAB EMIRATES (UAE)',\n",
       "       'SAMOA', 'AZORES', 'SOLOMON ISLANDS', 'SOUTH KOREA', 'MALTA',\n",
       "       'VIETNAM', 'MADAGASCAR', 'PANAMA', 'SOMALIA', 'NEVIS', 'CUBA',\n",
       "       'ENGLAND', 'BRITISH VIRGIN ISLANDS', 'NORWAY', 'SENEGAL', 'YEMEN',\n",
       "       'GULF OF ADEN', 'Sierra Leone', 'ST. MAARTIN', 'GRAND CAYMAN',\n",
       "       'Seychelles', 'LIBERIA', 'VANUATU', 'MEXICO ', 'HONDURAS',\n",
       "       'VENEZUELA', 'SRI LANKA', ' TONGA', 'URUGUAY', 'INDIA',\n",
       "       'MICRONESIA', 'CARIBBEAN SEA', 'OKINAWA', 'TANZANIA',\n",
       "       'MARSHALL ISLANDS', 'EGYPT / ISRAEL', 'NORTHERN ARABIAN SEA',\n",
       "       'HONG KONG', 'EL SALVADOR', 'ANGOLA', 'BERMUDA', 'MONTENEGRO',\n",
       "       'IRAN', 'TUNISIA', 'NAMIBIA', 'NORTH ATLANTIC OCEAN', 'PORTUGAL',\n",
       "       'SOUTH CHINA SEA', 'BANGLADESH', 'PALAU', 'WESTERN SAMOA',\n",
       "       'PACIFIC OCEAN ', 'BRITISH ISLES', 'GRENADA', 'IRAQ', 'TURKEY',\n",
       "       'SINGAPORE', 'NEW BRITAIN', 'SUDAN', 'JOHNSTON ISLAND',\n",
       "       'SOUTH PACIFIC OCEAN', 'NEW GUINEA', 'RED SEA',\n",
       "       'NORTH PACIFIC OCEAN', 'FEDERATED STATES OF MICRONESIA',\n",
       "       'MID ATLANTIC OCEAN', 'ADMIRALTY ISLANDS', 'BRITISH WEST INDIES',\n",
       "       'SOUTH ATLANTIC OCEAN', 'PERSIAN GULF', 'RED SEA / INDIAN OCEAN',\n",
       "       'PACIFIC OCEAN', 'NORTH SEA', 'NICARAGUA ', 'MALDIVE ISLANDS',\n",
       "       'AMERICAN SAMOA', 'ANDAMAN / NICOBAR ISLANDAS', 'GABON', 'MAYOTTE',\n",
       "       'NORTH ATLANTIC OCEAN ', 'THE BALKANS', 'SUDAN?', 'ARGENTINA',\n",
       "       'MARTINIQUE', 'INDIAN OCEAN', 'GUATEMALA', 'NETHERLANDS ANTILLES',\n",
       "       'NORTHERN MARIANA ISLANDS', 'IRAN / IRAQ', 'JAVA', 'SIERRA LEONE',\n",
       "       ' PHILIPPINES', 'NICARAGUA', 'CENTRAL PACIFIC',\n",
       "       'SOLOMON ISLANDS / VANUATU', 'SOUTHWEST PACIFIC OCEAN',\n",
       "       'BAY OF BENGAL', 'MID-PACIFC OCEAN', 'SLOVENIA', 'CURACAO',\n",
       "       'ITALY / CROATIA', 'BARBADOS', 'MONACO', 'GUYANA', 'HAITI',\n",
       "       'SAN DOMINGO', 'IRELAND', 'KUWAIT', 'LIBYA', 'YEMEN ',\n",
       "       'MEDITERRANEAN SEA?', 'FALKLAND ISLANDS', 'CRETE', 'CYPRUS',\n",
       "       'EGYPT ', 'BURMA', 'LEBANON', 'PARAGUAY', 'BRITISH NEW GUINEA',\n",
       "       'OCEAN', 'GEORGIA', 'SYRIA', 'TUVALU', 'INDIAN OCEAN?', 'GUINEA',\n",
       "       'EQUATORIAL GUINEA / CAMEROON', 'COOK ISLANDS', 'ALGERIA',\n",
       "       'Coast of AFRICA', 'TASMAN SEA', 'GHANA'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Over total</th>\n",
       "      <th>Cases by country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>36.2</td>\n",
       "      <td>2096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUSTRALIA</th>\n",
       "      <td>21.7</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>11.5</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOUTH AFRICA</th>\n",
       "      <td>9.6</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPUA NEW GUINEA</th>\n",
       "      <td>2.2</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEW ZEALAND</th>\n",
       "      <td>2.1</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRAZIL</th>\n",
       "      <td>1.8</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAHAMAS</th>\n",
       "      <td>1.6</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEXICO</th>\n",
       "      <td>1.4</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITALY</th>\n",
       "      <td>1.2</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIJI</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHILIPPINES</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REUNION</th>\n",
       "      <td>0.9</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEW CALEDONIA</th>\n",
       "      <td>0.9</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUBA</th>\n",
       "      <td>0.7</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPAIN</th>\n",
       "      <td>0.7</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOZAMBIQUE</th>\n",
       "      <td>0.7</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CROATIA</th>\n",
       "      <td>0.6</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JAPAN</th>\n",
       "      <td>0.6</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDIA</th>\n",
       "      <td>0.6</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGYPT</th>\n",
       "      <td>0.6</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PANAMA</th>\n",
       "      <td>0.5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOLOMON ISLANDS</th>\n",
       "      <td>0.5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRAN</th>\n",
       "      <td>0.4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  % Over total  Cases by country\n",
       "Country                                         \n",
       "USA                       36.2              2096\n",
       "AUSTRALIA                 21.7              1260\n",
       "Other                     11.5               729\n",
       "SOUTH AFRICA               9.6               557\n",
       "PAPUA NEW GUINEA           2.2               129\n",
       "NEW ZEALAND                2.1               124\n",
       "BRAZIL                     1.8               102\n",
       "BAHAMAS                    1.6                95\n",
       "MEXICO                     1.4                80\n",
       "ITALY                      1.2                67\n",
       "FIJI                       1.0                59\n",
       "PHILIPPINES                1.0                59\n",
       "REUNION                    0.9                55\n",
       "NEW CALEDONIA              0.9                51\n",
       "CUBA                       0.7                40\n",
       "SPAIN                      0.7                38\n",
       "MOZAMBIQUE                 0.7                42\n",
       "CROATIA                    0.6                34\n",
       "JAPAN                      0.6                32\n",
       "INDIA                      0.6                32\n",
       "EGYPT                      0.6                36\n",
       "PANAMA                     0.5                29\n",
       "SOLOMON ISLANDS            0.5                27\n",
       "IRAN                       0.4                25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # 2) Analyzing Country column\n",
    "\n",
    "print(\"Showing unique values for Country column\\n\")\n",
    "display(df[\"Country\"].unique())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Action: we will check cases by country and show only values for the main countries.\n",
    "    # The rest will be classified as \"Other\" in a separated dataframe\n",
    "\n",
    "df_by_country = df.groupby('Country').Country.count().sort_values(ascending = False)\n",
    "perc_by_country = round((df_by_country / df_by_country.sum() * 100), 1)\n",
    "df_by_country = pd.DataFrame({\"Cases by country\": df_by_country, \"% Over total\": perc_by_country})\n",
    "df_by_country.reset_index(inplace=True)\n",
    "df_by_country.loc[df_by_country['Cases by country'] < 25, ['Country']] = 'Other'\n",
    "df_by_country = df_by_country.groupby(['Country'])[\"% Over total\", \"Cases by country\"].sum()\n",
    "df_by_country.sort_values(by=[\"% Over total\"], inplace= True, ascending = False)\n",
    "display(df_by_country)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing unique values for Activity column\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Activity\n",
       "Surfing                                                                   902\n",
       "Swimming                                                                  796\n",
       "Fishing                                                                   405\n",
       "Spearfishing                                                              321\n",
       "Bathing                                                                   147\n",
       "Wading                                                                    141\n",
       "Diving                                                                    111\n",
       "Standing                                                                   95\n",
       "Snorkeling                                                                 76\n",
       "Scuba diving                                                               73\n",
       "Body boarding                                                              54\n",
       "Body surfing                                                               48\n",
       "Swimming                                                                   46\n",
       "Treading water                                                             32\n",
       "Kayaking                                                                   28\n",
       "Boogie boarding                                                            28\n",
       "Pearl diving                                                               26\n",
       "Free diving                                                                24\n",
       "Fell overboard                                                             21\n",
       "Windsurfing                                                                18\n",
       "Boogie Boarding                                                            16\n",
       "Walking                                                                    15\n",
       "Shark fishing                                                              15\n",
       "Fishing                                                                    12\n",
       "Surf skiing                                                                12\n",
       "Surf-skiing                                                                12\n",
       "Floating                                                                   12\n",
       "Rowing                                                                     12\n",
       "Canoeing                                                                   11\n",
       "Surf fishing                                                               11\n",
       "                                                                         ... \n",
       "Shipwrecked; adrift on raft for 2 days & 2 nights                           1\n",
       "Shrimping                                                                   1\n",
       "Sight-seeing                                                                1\n",
       "Sinking of the 40' Esperanza off St. Maartin with 36 refugees on board      1\n",
       "Sinking of the M/V Mindoro during a typhoon                                 1\n",
       "Sinking of the cargo ship Mark Jason                                        1\n",
       "Sinking of the dredge World Atlas                                           1\n",
       "Sinking of the ferryboat      Don Juan                                      1\n",
       "Sinking of the ferryboat Bongbong 1                                         1\n",
       "Shark fishing on the Ricardo Astorga                                        1\n",
       "Shark fishing on the Don AgustÃ­n-VI.                                        1\n",
       "Shark Fishing                                                               1\n",
       "Sea Disaster, sinking of the  SS Vestris                                    1\n",
       "Scuba diving, but swimming on surface                                       1\n",
       "Scuba diving, hand feeding sharks                                           1\n",
       "Scuba diving, reportedly also spearfishing                                  1\n",
       "Scurfing (surfboard being  towed behind a boat)                             1\n",
       "Sea Disaster : Wreck of the Carrie E. Long                                  1\n",
       "Sea Disaster Sinking of ferryboat Christina                                 1\n",
       "Sea Disaster, canoes capsized in storm                                      1\n",
       "Sea Disaster, sinking of the fishing  launch Mavis                          1\n",
       "Setting crayfish pots                                                       1\n",
       "Sea Disaster, sinking of the motorship Wingate                              1\n",
       "Sea Disaster, wreck of the  SS Norwich City                                 1\n",
       "Sea disaster : Wreck of the Taiaroa                                         1\n",
       "Sea disaster, foundering of the cargo vessle M/V Dorolonda                  1\n",
       "Sea disaster, wreck of the Alfred Watts                                     1\n",
       "Searching for remains of  Dr. Marais                                        1\n",
       "Seining for bait, standing in chest-deep water                              1\n",
       "                                                                            1\n",
       "Name: Activity, Length: 1449, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'Activity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2566\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlibts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2567\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.get_value_box\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.get_value_box\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-370-58d205676f39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#First, we will re-classify activities with less than 10 ocurrences as \"Other\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf_by_activity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_by_activity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Activity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Activity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Other'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_by_activity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2572\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2573\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2574\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2575\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2576\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2558\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 2560\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   2561\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Activity'"
     ]
    }
   ],
   "source": [
    "# 3) Analyzing Activity column\n",
    "\n",
    "print(\"Showing unique values for Activity column\\n\")\n",
    "#print(set(list(df[\"Activity\"])))\n",
    "display(df_by_activity)\n",
    "\n",
    "    #First, we will re-classify activities with less than 10 ocurrences as \"Other\"\n",
    "\n",
    "df_by_activity.loc[df_by_activity['Activity'].count() > 11, ['Activity']] = 'Other'\n",
    "display(df_by_activity)\n",
    "\n",
    "    #First, we will rename fields with following criteria:\n",
    "    # a) If contains swimming, rename to Swimming\n",
    "    # b) If contains diving, rename to Diving\n",
    "    # c) If contains surf, rename to Surfing\n",
    "\n",
    "    # Action: We will substitute ... by UNKNOWN\n",
    "\n",
    "#df.loc[df['Activity'] ==  ..., ['Activity']] = 'UNKNOWN'\n",
    "#display(df[\"Activity\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Showing unique values for Injury column\\n\")\n",
    "print(\"Action: We will substitute ... by UNKNOWN\\n\")\n",
    "display(df[\"Injury\"].unique())\n",
    "print(\"Action: There is info about if Injury was Fatal. We will double check with column Fatal (Y/N)\\n\")\n",
    "print(\"Showing unique values for Fatal (Y/N) column\\n\")\n",
    "display(df[\"Fatal (Y/N)\"].unique())\n",
    "print(\"Action: We will substitute ... by UNKNOWN\\n\")\n",
    "display(df[(df[\"Injury\"].str.contains(\"FATAL\", na = False)) & (df[\"Fatal (Y/N)\"] == \"N\")])\n",
    "print(\"\\n There is a FATAL case reported as not FATAL, so we will correct this.\")\n",
    "\n",
    "\n",
    "#df.loc[5872, \"Fatal (Y/N)\"] = \"Y\"\n",
    "#display(df[(df[\"Injury\"].str.contains(\"FATAL\", na = False)) & (df[\"Fatal (Y/N)\"] == \"N\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
